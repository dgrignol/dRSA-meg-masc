# MEG-MASC dRSA Analysis Pipeline Guide

This document summarises how to run the MEG-MASC processing scripts (from preprocessing to dRSA), how to combine them with the pipeline wrappers, and how to submit the full workflow to an SGE cluster. Every command below assumes you execute it from the repository root with the desired Python environment activated (e.g. `source .venv/bin/activate`). All scripts expose `--help`; consult it for the definitive option list.

---

## 1. Prerequisites

- **Python environment** – install dependencies with `pip install -r requirements.txt`. Most scripts rely on `mne`, `numpy`, `scipy`, `matplotlib`, and a handful of audio/text libraries. Activate the local virtual environment (`source .venv/bin/activate`) before running any script, or call its interpreter explicitly (e.g. `./.venv/bin/python D1_group_cluster_analysis.py --subjects $(seq -w 1 2)`). No manual `PYTHONPATH` tweaks are required. On the cluster, activate the micromamba env: `micromamba activate drsa311  # or whichever env has Python 3`, then run your script.
- **Data layout** – the anonymised BIDS dataset must live in `bids_anonym/`. All derivatives are created inside `derivatives/`, and dRSA outputs are stored in named subfolders under `results/<analysis_name>/` (`single_subjects/` and `group_level/`).
- **GloVe embeddings** – scripts that touch word embeddings (B4 and the wrappers) require a plain-text GloVe file (e.g. `glove.6B.300d.txt`). Store its path in `glove_path.txt`, set `$GLOVE_PATH`, or pass `--glove-path`.

---

## 2. Stage-by-stage scripts

### A1_preprocess_data.py
Minimal preprocessing plus sentence masking for every BIDS run.

- **Input**: Raw MEG runs under `bids_anonym/`.
- **Output**: Preprocessed FIF files, sentence masks, audio waveforms, and metadata in `derivatives/preprocessed/sub-XX/ses-*/task-*/`.
- **Key options**
  - `--subjects 01 02 …` – limit processing to specific subjects (default: all available).
  - `--overwrite` – overwrite existing derivatives.
  - `--log-level {DEBUG,INFO,…}` – adjust verbosity.
- **Usage**
  ```bash
  python A1_preprocess_data.py --subjects 02 03 --overwrite
  python A1_preprocess_data.py --log-level DEBUG
  ```

### A2_concatenate_subject_data.py
Concatenates per-run derivatives into subject-level arrays and audio files.

- **Input**: Outputs from A1 in `derivatives/preprocessed`.
- **Output**: `*_concatenated_*` files beneath `derivatives/preprocessed/sub-XX/concatenated/`, plus provenance JSON.
- **Key options**
  - `--derivatives-root PATH` – override the derivatives directory (default `derivatives`).
  - `--subject sub-03` – subject to process (default `sub-01`).
  - `--overwrite` – replace existing concatenated outputs.
- **Usage**
  ```bash
  python A2_concatenate_subject_data.py --subject sub-05 --overwrite
  python A2_concatenate_subject_data.py --derivatives-root /tmp/derivatives --subject 07
  ```

> **Note**: A3 (`A3_resample_concatenated_data.py`) is automatically invoked by both pipeline wrappers to downsample the concatenated files. Run it manually if you skip the wrappers.

### check_word_onset_extraction.py
Quick visual check that the concatenated word onsets exported by A2 align with the audio envelope and sentence mask. 

- **Input**:
`derivatives/preprocessed/<subject>/concatenated/<subject>_concatenated_word_onsets_sec.npy` (from A2_concatenate_subject_data.py), `*_concatenated_sentence_mask_100Hz.npy` (from A2_concatenate_subject_data.py), and the 100 Hz speech envelope at `derivatives/Models/envelope/<subject>/concatenated/<subject>_concatenated_envelope_100Hz.npy` (from B1_model_envelope.py).
- **Output**: `word_onsets.png` in the current directory showing:
  - mean envelope (blue),
  - shaded regions where the sentence mask is active,
  - vertical markers at every extracted word onset.
- **Usage**
  ```bash
  python check_word_onset_extraction.py          # defaults to sub-01 and saves word_onsets.png
  python check_word_onset_extraction.py --help   # edit the script to point at other subjects
  ```
- Adjust `subject` and `time_window` at the top of the script to explore different participants or time spans.


### B1_model_envelope.py
Builds broadband gammatone speech envelopes for every run and subject.

- **Input**: Audio + metadata generated by A1.
- **Output**: Envelope arrays in `derivatives/Models/envelope/`, concatenated subject-level envelopes, and optional reports under `derivatives/reports/`.
- **Key options**
  - `--subjects 01 02` – subset to process (default: all).
  - `--overwrite` – regenerate envelopes and reports.
  - `--log-level` – adjust verbosity.
- **Usage**
  ```bash
  python B1_model_envelope.py --subjects 02 03
  python B1_model_envelope.py --overwrite --log-level DEBUG
  ```

### B2_wordfreq.py
Generates word-frequency trajectories aligned to MEG timepoints.

- **Input**: Preprocessed metadata (A1) and BIDS events.
- **Output**: Per-run arrays in `derivatives/Models/wordfreq/` plus optional concatenated and resampled subject-level series.
- **Key options**
  - `--subjects …` – restrict processing.
  - `--overwrite` – replace existing outputs.
  - `--no-concat` – skip subject-level concatenation/resampling.
  - `--target-rate 100` – resample concatenated arrays to a desired rate (Hz).
  - `--plot` / `--plot-max-points` – emit diagnostic plots.
- **Usage**
  ```bash
  python B2_wordfreq.py --subjects 02 03 --target-rate 100 --plot
  python B2_wordfreq.py --overwrite --no-concat
  ```

### B3_voicing.py
Creates phoneme voicing (+1/-1) trajectories aligned with MEG timepoints.

- **Input**: A1 derivatives, BIDS events, and `phoneme_info.csv`.
- **Output**: Per-run voicing arrays (`derivatives/Models/voicing/`), optional concatenated/resampled series, and optional plots.
- **Key options** mirror B2:
  - `--subjects`, `--overwrite`, `--no-concat`, `--target-rate`, `--plot`, `--plot-max-points`, `--log-level`.
- **Usage**
  ```bash
  python B3_voicing.py --subjects 02 03 --target-rate 100 --plot
  python B3_voicing.py --overwrite --no-concat
  ```

### B4_glove.py
Builds subject-level GloVe embedding trajectories on a 100 Hz grid.

- **Input**: Concatenation metadata, BIDS word events, and a GloVe text file.
- **Output**: `*_concatenated_glove_100Hz.npy` (memmap-friendly), metadata JSON, and optional diagnostic plots under `derivatives/Models/glove/`.
- **Key options**
  - `--subjects …` – subset of subjects (default: all).
  - `--glove-path /path/to/glove.6B.300d.txt` – **required** unless configured via `GLOVE_PATH` or `glove_path.txt`.
  - `--target-rate 100` – sampling rate for the output (default 100 Hz).
  - `--overwrite`, `--random-seed`, `--plot`, `--plot-max-points`, `--log-level`.
- **Usage**
  ```bash
  python B4_glove.py --subjects 02 03 --glove-path ~/data/glove.6B.300d.txt
  python B4_glove.py --glove-path ./glove.840B.300d.txt --target-rate 50 --plot
  ```

### C1_dRSA_run.py
Runs the subject-level dynamic RSA analysis. In addition to the legacy streaming correlation metric, the Python implementation now supports PCR, Ridge, Lasso, and Elastic Net regression for estimating each model’s unique variance. Non-correlation modes cache the full neural/model RDM stacks (in RAM or via memmaps, depending on `--regression-mem-threshold-gb`) and log PCA usage/R² summaries for long cluster jobs.

- **Input**: Concatenated MEG, masks, and all model trajectories (envelope, word frequency, voicing, GloVe).
- **Output** per subject:
  - Standard runs → `results/<analysis_name>/single_subjects/` (matrices, metadata, plots, cache PNG).
  - Simulation runs → `results/<analysis_name>/simulations/` (one metadata/plot per simulation plus an optional autocorrelation summary; caches still live under `single_subjects/cache/` so subsamples remain shared).
  - Filenames follow `sub-XX_res100_correlation[_sim_##_<LABEL>]_*.{npy,json,png}`. Metadata always records the resolved paths so C2 can find them.
- **Key options**
  - `subject` – positional subject label or integer.
  - `--analysis-name NAME` – recommended; names the analysis folder under `results/` (default: timestamp such as `20240130_143210`).
  - `--results-root PATH` – parent directory that will contain the analysis folder (default: `results`).
  - `--lock-subsample-to-word-onset` – restrict subsample starts to the concatenated word onset timestamps (requires the numpy file written by A2).
  - `--word-onset-alignment {center,start}` – when locking, center windows on each onset (default) or start them at the onset to reproduce the legacy behavior.
  - `--allow-overlap` – allow subsample windows to overlap (handy when the onset density is low; compatible with and without locking).
  - `--regression-method {correlation,pcr,ridge,lasso,elasticnet}` – choose the model–neural fitting strategy (default: `elasticnet`, which isolates each model’s unique contribution by regularised multi-model regression). Set `correlation` to stream the classic Pearson metric without storing full RDM stacks.
  - `--regression-alpha` – regularisation strength for Ridge/Lasso/Elastic Net (default 1.0). Tweak per subject or pass different values via the pipeline wrapper’s `EXTRA_ARGS`.
  - `--regression-l1-ratio` – Elastic Net mixing parameter between L1 (1.0) and L2 (0.0); ignored by other methods.
  - `--pcr-variance-threshold` – cumulative variance PCs must explain when `--regression-method=pcr` (default 0.85).
  - `--regression-border-threshold` – lag-autocorrelation threshold (default 0.1) used to drop same-model predictors near zero lag, matching the MATLAB `dRSA_border.m` logic.
  - `--regression-mem-threshold-gb` – per-buffer size limit (default 2 GiB) above which the intermediate RDM stacks spill to disk via memmaps. Set this higher on machines with ample RAM to keep everything in memory; leave as-is on shared clusters.
  - `--plot-regression-borders/--no-plot-regression-borders` – save (default) or skip PNG diagnostics of each model’s autocorrelation with the derived regression borders overlaid. Files land under `results/<analysis_name>/single_subjects/cache/regression_borders/`.
  - `--progress-log-every N` – stream a status message every N subsampling iterations while buffering/regressing (default 10). Handy when monitoring long cluster jobs.
  - `--progress-neural-step N` – during the regression phase, log after every N neural time points per iteration (default 50). Lower values provide finer-grained updates at the cost of chattier logs.
  - `--simulation` – reuse the cached subsamples but swap the neural input: (1) run MEG×MEG once (neural autocorrelation only) and (2) run each model as the “neural” source against the full model set. Outputs land in `results/<analysis_name>/simulations/`. If that folder already contains the `_sim_*` metadata for the requested subject, the script exits immediately and prints where to find the existing plots instead of recomputing. (The skip is all-or-nothing: as soon as one simulation metadata file exists for the subject, the loop is bypassed. Delete or move the previous simulation outputs if you need to regenerate them.)

> **Per-model regression borders:** you can set different autocorrelation thresholds per model directly in `C1_dRSA_run.py` by passing the optional `regression_border=<value>` argument to `_register_model(...)`. The helper signature is `_register_model(path, label, metric, regression_border=None)`. When omitted, the global `--regression-border-threshold` applies; when provided, that specific model’s border plot and regression exclusion mask use the supplied value (e.g., `0.05` for a wider window, `0.2` for a tighter one).
- **Usage**
  ```bash
  # Preferred: explicit analysis name reused across scripts
  python C1_dRSA_run.py sub-02 --analysis-name lexical_mem_2024

  # Quick run: auto-generate a timestamped folder under results/
  python C1_dRSA_run.py 03

  # Simulation sweep for subject 01 (reuses subsamples, writes to results/<analysis>/simulations/)
  python C1_dRSA_run.py sub-01 --analysis-name center_on_onset_overlap \
    --lock-subsample-to-word-onset --allow-overlap --simulation
  ```
- **Word onset workflows**: When `derivatives/preprocessed/<subject>/concatenated/<subject>_concatenated_word_onsets_sec.npy` exists, C1 hashes the timestamps for caching, records their provenance inside the metadata JSON, and overlays them on the subsampling QC figure. Passing `--lock-subsample-to-word-onset` enforces that every subsample window is anchored to a word onset; the window is centered on the onset by default, and `--word-onset-alignment start` reproduces the legacy start-aligned behavior. Toggling `--lock-subsample-to-word-onset`, `--word-onset-alignment`, or `--allow-overlap` automatically invalidates the subsample cache so reruns remain reproducible.
- **Tuning**: Edit the constants near the bottom of the file (e.g., `averaging_diagonal_time_window_sec`, `n_subsamples`) to adjust the analysis.

### C2_plot_dRSA.py
Recreates subject-level dRSA figures from cached matrices and lag curves using the same layout as the group-level plots.

- **Input**: The metadata JSON plus the `*_dRSA_matrices.npy` and optional `*_lag_curves.npy` generated by C1. The script automatically scans both `results/<analysis_name>/single_subjects/` and `results/<analysis_name>/simulations/` so the same command can replot standard and simulation runs.
- **Output**: One 2×N subplot figure per neural signal (PNG, 300 dpi) saved next to the matrices. Simulation jobs also receive an aggregate `sub-XX_res100_correlation_sim_autocorrelations_plot.png` that stacks each model’s self-correlation (or the neural autocorrelation) for quick inspection.
- **Key options**
  - `subject` (positional) – subject label (`sub-02`) or integer (`2`).
  - `--analysis-name NAME` – analysis folder to read from (defaults to the latest available run under `--results-root`).
  - `--results-root PATH` – parent directory containing named analyses (default `results`).
  - `--analysis-id` – override the subject/resolution/method trio with an explicit run ID (bypasses `--analysis-name`).
  - `--resolution`, `--rsa-method` – only needed when reconstructing legacy layouts or using `--analysis-id`.
  - `--results-dir` – legacy override pointing directly to subject outputs.
- **Usage**
  ```bash
  # Preferred: reuse the analysis name chosen for C1
  python C2_plot_dRSA.py sub-01 --analysis-name lexical_mem_2024

  # Quick check: fall back to the most recent analysis automatically
  python C2_plot_dRSA.py sub-01

  # Plot both standard outputs and all simulations for subject 01
  python C2_plot_dRSA.py sub-01 --analysis-name center_on_onset_overlap
  ```
- **Notes**
  - When lag bootstrap samples are available, the script overlays the mean lag curve with a confidence band.
  - Each figure mirrors the styling of `D1_group_cluster_analysis.py`, making per-subject and group-level outputs visually consistent.

### D1_group_cluster_analysis.py
Aggregates subject dRSA results, performs a cluster-based permutation test, and generates summary figures.

- **Input**: Subject-level outputs from C1 located in `results/<analysis_name>/single_subjects/`.
- **Output** (one set per neural signal reported in the metadata) written to `results/<analysis_name>/group_level/`:
  - `group_dRSA_summary_<NEURAL_LABEL>.png` (raster, 300 dpi)
  - `group_dRSA_summary_<NEURAL_LABEL>.pdf` (vector export for Illustrator)
  - `group_dRSA_summary_<NEURAL_LABEL>.npz` (cache containing all aggregated arrays and settings)
- **Key options**
  - `--analysis-name NAME` – analysis folder to read/write (default: latest analysis under `--results-root`).
  - `--results-root PATH` – parent directory containing analyses (default `results`).
  - `--subjects`, `--models`, `--lag-metric`, `--cluster-alpha`, `--permutation-alpha`, `--n-permutations` – unchanged.
  - `--force-matrix-clusters` – force matrix-level cluster permutation even when subsamples are not word-onset locked (auto-enabled when metadata reports `lock_subsample_to_word_onset=True`).
  - `--skip-matrix-clusters` – bypass matrix-level permutation tests even if they would normally run (useful for quick smoke checks or when only lag curves are needed).
  - `--matrix-downsample-factor INT` – average matrices over INT×INT blocks before the permutation test (default 1, i.e. no downsampling).
  - `--results-dir` – legacy override pointing directly to subject-level outputs.
- **Usage**
  ```bash
  # Preferred: explicit analysis
  python D1_group_cluster_analysis.py \
    --analysis-name lexical_mem_2024 \
    --subjects $(seq -w 1 27) \
    --models "Envelope" "Phoneme Voicing" "Word Frequency" "GloVe" "GloVe Norm"

  # Default: reuse the most recent analysis automatically
  python D1_group_cluster_analysis.py --subjects $(seq -w 1 10) --models Envelope "GloVe"

  # Force matrix-level clusters even for unlocked subsamples
  python D1_group_cluster_analysis.py \
    --analysis-name lexical_mem_2024 \
    --subjects $(seq -w 1 27) \
    --models "Envelope" "GloVe" \
    --force-matrix-clusters
  ```

  The `<NEURAL_LABEL>` suffix is derived from `metadata["neural_signal_labels"]` for the first subject. Spaces are converted to underscores (e.g., `MEG Full 1 → MEG_Full_1`). The figure title also includes the full label, so expect separate outputs such as `Group-level dRSA summary | MEG Full 2`. If only a single neural signal is present, the suffix still uses the label to keep filenames explicit.
  When using multiple neural signals, rerun the `--plot-only` command with each cache file produced during the initial analysis.

- **Matrix-level cluster analysis**
  - When subject metadata indicates `lock_subsample_to_word_onset=True`, the script performs 2D cluster permutation tests on the group dRSA matrices in addition to the lag curves. Significant matrix clusters are outlined in white on the heatmaps and stored in the `.npz` cache.
  - Use `--force-matrix-clusters` to run the matrix permutation even if the metadata shows unlocked subsamples (default off). The `--skip-matrix-clusters` flag does the opposite by disabling the matrix test altogether, regardless of the metadata.
  - The `--n-permutations` value applies to both lag and matrix tests.
  - `--matrix-downsample-factor` reduces matrix resolution before cluster testing (e.g., `--matrix-downsample-factor 2` averages 2×2 blocks for ~75% faster permutations; `--matrix-downsample-factor 4` averages 4×4 blocks for ~94% faster permutations; larger factors scale roughly with 1/factor²). The resulting significant blocks are projected back onto the full-resolution heatmap for plotting.
  - Matrix permutation results are cached alongside the usual averages so replotting with `--plot-only` reproduces the overlays without recomputation.
- **Logging**
  - Default verbosity is now `DEBUG`, which prints progress messages at the 10th permutation and every subsequent 100 iterations for both lag and matrix cluster loops. Switch to `--log-level INFO` (or higher) to suppress detailed progress reporting.

---

## 3. Pipeline wrappers

### pipeline_wrapper.py – full pipeline
Runs every step (A1→D1) for the chosen subjects without deleting intermediates.

- **Essential options**
  - `--subjects 2-23 25` – required; supports comma/space-separated IDs and ranges.
  - `--glove-path` – optional if `$GLOVE_PATH` or `glove_path.txt` is configured.
  - `--overwrite` – forwards the flag to individual scripts.
  - `--continue-on-error` – keep running even if a step fails.
  - `--group-subjects` – override the subject list passed to D1.
  - `--analysis-name NAME` – recommended; names the results folder reused by C1/D1 (default: timestamp).
  - `--lock-subsample-to-word-onset`, `--allow-overlap` – forward the subsampling controls to C1 when set.
  - `--results-root PATH`, `--lag-metric`, `--models`, `--d1-output`, `--d1-n-permutations`.
  - `--log-level`.
- **Examples**
  ```bash
  # Full cohort with explicit GloVe path
  python pipeline_wrapper.py --subjects 2-23 --glove-path /data/glove.6B.300d.txt --analysis-name lexical_mem_2024

  # Rerun a subset, overwriting intermediates and forcing D1 to use custom models
  python pipeline_wrapper.py \
    --subjects 05 06 \
    --overwrite \
    --analysis-name lexical_mem_debug \
    --models Envelope "Word Frequency" GloVe \
    --group-subjects 05 06
  ```

### pipeline_wrapper_low_storage.py – sequential, low-footprint mode
Processes subjects one at a time, pruning bulky intermediates after C1 (native-rate concatenates, run-level FIF files, and redundant model arrays) while keeping the 100 Hz subject-level data needed for future dRSA reruns. After the per-subject loop it runs D1 on the successful subset.

- **Essential options**
  - `--subjects …` (required) – same syntax as the full wrapper.
  - `--glove-path` – required if not configured globally.
  - `--overwrite`, `--continue-on-error`.
  - `--keep-derivatives` – skip cleanup for debugging.
  - `--keep-reports` – keep HTML/PDF reports while still removing large arrays.
  - `--analysis-name NAME` – recommended; ensures every subject writes into the same results folder (default: timestamp).
  - `--lock-subsample-to-word-onset`, `--allow-overlap` – forward onset locking/overlap flags to C1 before pruning intermediates.
  - `--results-root`, `--models`, `--lag-metric`, `--d1-output`, `--d1-n-permutations`, `--log-level`.
- **Examples**
  ```bash
  python pipeline_wrapper_low_storage.py \
    --subjects 2-23 \
    --glove-path /data/glove.6B.300d.txt \
    --analysis-name lexical_mem_2024 \
    --continue-on-error \
    --keep-reports

  # Debug a single subject without deleting any derivatives
  python pipeline_wrapper_low_storage.py \
    --subjects 07 \
    --glove-path /data/glove.6B.300d.txt \
    --analysis-name lexical_mem_debug \
    --keep-derivatives --log-level DEBUG
  ```

---

## 4. Cluster submission scripts

Eight helper scripts show how to submit common workloads to SGE:

- `s2_submit_A1_preproc.sh` – array job that assigns one subject per task for A1 preprocessing.
- `s2_submit_A2_concat.sh` – array job that runs A2 concatenation subject by subject.
- `s2_submit_A3_resample.sh` – array job that resamples concatenated derivatives (A3).
- `s2_submit_C1_subject.sh` – array job that runs the C1 dRSA analysis per subject.
- `s2_submit_C2_plot.sh` – single job that renders the group/subject plots (C2).
- `s2_submit_python_wrapper.sh` – legacy full-pipeline submission (kept for reference).
- `s2_submit_python_wrapper_low_storage.sh` – sequential wrapper variant that prunes intermediates after each subject.
- `s2_submit_D1_group.sh` – runs only the group-level dRSA aggregation (D1) once all per-subject outputs exist.

General checklist:

1. **Adjust paths** – update `WD` (repository root on the cluster) and any resource paths such as `GLOVE`.
2. **Environment** – the scripts assume `micromamba activate drsa311`. Swap in your own environment activation if needed.
3. **Resources** – tweak `#$` directives (`-pe`, `-l h_vmem`, runtime limits, etc.) to match your quota and job size.
4. **Command** – edit the final `python …` line(s) with the exact arguments you would use locally (e.g., subject list, models, permutation count).
5. **Submission** – make the script executable (e.g., `chmod +x s2_submit_A1_preproc.sh`) and submit via `qsub`:
   ```bash
   qsub s2_submit_A1_preproc.sh              # subject-wise preprocessing
   qsub s2_submit_A2_concat.sh               # subject-wise concatenation
   qsub s2_submit_A3_resample.sh             # subject-wise resampling (A3)
   qsub s2_submit_C1_subject.sh              # subject-wise dRSA (C1)
   qsub s2_submit_C2_plot.sh                 # generate plots (C2)
   qsub s2_submit_python_wrapper_low_storage.sh    # per-subject loop
   qsub s2_submit_D1_group.sh                      # group aggregation only
   ```
   Except for `s2_submit_D1_group.sh`, each helper tolerates an optional leading `--` before additional script arguments so you can keep `qsub` flags separate. For `s2_submit_D1_group.sh` pass extra options directly (no separator) so they reach `D1_group_cluster_analysis.py`.

### s2_submit_A1_preproc.sh – preprocessing array job
Runs `A1_preprocess_data.py` with the subject ID derived from `SGE_TASK_ID`. The script ships with `#$ -t 1-27`, so submitting without extra arguments spawns one task per subject (01–27). Override the range at submit time to target specific participants.

```bash
qsub s2_submit_A1_preproc.sh           # run all subjects (1–27)
qsub -t 2 s2_submit_A1_preproc.sh      # only subject 02
qsub -t 10-15 s2_submit_A1_preproc.sh  # subjects 10–15
```

Each task writes logs to `logs/A1_preproc.<jobid>.<taskid>.{out,err}`.

### s2_submit_A2_concat.sh – concatenation array job
Runs `A2_concatenate_subject_data.py` subject by subject using the same array pattern as the preprocessing script.

```bash
qsub s2_submit_A2_concat.sh           # run concatenation for subjects 01–27
qsub -t 2 s2_submit_A2_concat.sh      # only subject 02
qsub -t 5,7,9 s2_submit_A2_concat.sh  # run a sparse set of subjects
```

Logs are stored per task in `logs/A2_concat.<jobid>.<taskid>.{out,err}`.

### s2_submit_A3_resample.sh – resampling array job
Runs `A3_resample_concatenated_data.py` to downsample concatenated MEG/mask files per subject. Pass extra options (e.g., `--target-rate`) after an optional separating `--`.

```bash
qsub s2_submit_A3_resample.sh                               # subjects 01–27
qsub -t 2 s2_submit_A3_resample.sh                          # only subject 02
qsub -t 5-9 s2_submit_A3_resample.sh -- --target-rate 200   # custom output rate
```

Outputs inherit the base script’s naming (`*_concatenated_meg_<suffix>.npy`) beneath each subject’s `derivatives/preprocessed/.../concatenated/` directory.

### s2_submit_C1_subject.sh – subject-level dRSA array job
Runs `C1_dRSA_run.py` for each subject listed in the array range. The helper appends `--analysis-name` automatically, sourcing the value from `ANALYSIS_NAME` (if set) or falling back to `drsa_$JOB_ID`. Extra CLI arguments passed after an optional separating `--` (to keep `qsub` happy) are forwarded to the Python script.

```bash
qsub s2_submit_C1_subject.sh                         # run subjects 01–27 (defaults to drsa_$JOB_ID)
qsub -t 2 s2_submit_C1_subject.sh                    # only subject 02
qsub -t 5-9 s2_submit_C1_subject.sh -- --analysis-name lexical_mem_2024   # explicit folder
qsub s2_submit_C1_subject.sh -- --lock-subsample-to-word-onset --allow-overlap # extra flags
qsub s2_submit_C1_subject.sh -- --analysis-name lock_to_onset_overlap --lock-subsample-to-word-onset --allow-overlap
```

Logs land in `logs/C1_dRSA.<jobid>.<taskid>.{out,err}`. When passing optional flags remember to include the separator if you supply additional `qsub` options:

```bash
qsub -t 5-9 s2_submit_C1_subject.sh -- --lock-subsample-to-word-onset --allow-overlap
```

### s2_submit_C2_plot.sh – dRSA plotting array job
Runs `C2_plot_dRSA.py` per subject using the array index to derive the label. If neither `--analysis-name` nor `$ANALYSIS_NAME` is provided, the helper resolves the latest analysis under `results/`. Pass additional plotting options after an optional `--`.

```bash
qsub s2_submit_C2_plot.sh                     # render plots for subjects 01–27 (latest analysis)
qsub -t 2 s2_submit_C2_plot.sh                # only subject 02
qsub -t 5-9 s2_submit_C2_plot.sh -- --analysis-name lexical_mem_2024
```

Logs are stored in `logs/C2_plot.<jobid>.<taskid>.{out,err}`.

**Example**: to run D1 over subjects 01–27 with the default model set:
```bash
python D1_group_cluster_analysis.py \
  --analysis-name lexical_mem_2024 \
  --subjects $(seq -w 1 27) \
  --models "Envelope" "Phoneme Voicing" "Word Frequency" "GloVe" "GloVe Norm" \
  --lag-metric correlation
```
Mirror that command in `s2_submit_D1_group.sh` before submitting.

Logs from the cluster run are written to `logs/<jobname>.<jobid>.{out,err}` as configured at the top of each script.

---

## 5. Tips and troubleshooting

- Use `--log-level DEBUG` when debugging a stage; most scripts print detailed progress and file paths at that level.
- When rerunning D1 with the same settings, prefer `--plot-only` to skip the (potentially lengthy) permutation test.
- The wrappers propagate failures—check the `results/` directory after a run to verify that every subject produced both the matrix (`*_dRSA_matrices.npy`) and metadata files.
- For ad-hoc experimentation, run individual scripts with `--help` to see defaults and optional features not covered above.

---

## Summary Workflow (A1 → D1)

Use this checklist to drive the entire pipeline with consistent analysis folders. Commands are shown for direct execution and, when available, the corresponding SGE helpers. Replace subject lists, model choices, and paths to suit your experiment.

1. **Initial setup**
   - Direct:  
     ```bash
     cd /mnt/storage/tier2/morwur/Projects/DAMIANO/SpeDiction/meg-masc
     export ANALYSIS_NAME=lexical_mem_fullrun_$(date +%Y%m%d_%H%M%S)
     ```
   - SGE note: propagate the variable with `qsub -v ANALYSIS_NAME="$ANALYSIS_NAME" …` (or add `#$ -v ANALYSIS_NAME` to the script header). SGE does not support a `-ANALYSIS_NAME` flag.

2. **A1 – Preprocess raw MEG runs**
   - Direct: `python A1_preprocess_data.py --subjects 01 02 --overwrite`
   - Output: `derivatives/preprocessed/sub-XX/ses-*/task-*/…`
   - SGE: `qsub -v ANALYSIS_NAME="$ANALYSIS_NAME" -t 1-27 s2_submit_A1_preproc.sh -- --overwrite`

3. **A2 – Concatenate derivatives**
   - Direct: `python A2_concatenate_subject_data.py --subject sub-01 --overwrite`
   - Output: `derivatives/preprocessed/sub-XX/concatenated/*_concatenated_*`
   - SGE: `qsub -v ANALYSIS_NAME="$ANALYSIS_NAME" -t 1-27 s2_submit_A2_concat.sh -- --overwrite`

4. **A3 – Resample concatenates (100 Hz)**
   - Direct: `python A3_resample_concatenated_data.py --subject sub-01 --target-rate 100 --overwrite`
   - Output: 100 Hz MEG/mask arrays in the concatenated directory
   - SGE: `qsub -v ANALYSIS_NAME="$ANALYSIS_NAME" -t 1-27 s2_submit_A3_resample.sh -- --target-rate 100 --overwrite`

5. **B1 – Speech envelopes**
   - Direct: `python B1_model_envelope.py --subjects 01 02 --target-rate 100 --overwrite`
   - Output: `derivatives/Models/envelope/sub-XX/...`

6. **B2 – Word frequency trajectories**
   - Direct: `python B2_wordfreq.py --subjects 01 02 --target-rate 100 --overwrite`
   - Output: `derivatives/Models/wordfreq/sub-XX/...`

7. **B3 – Phoneme voicing**
   - Direct: `python B3_voicing.py --subjects 01 02 --target-rate 100 --overwrite`
   - Output: `derivatives/Models/voicing/sub-XX/...`

8. **B4 – GloVe embeddings**
   - Direct:  
     ```bash
     python B4_glove.py \
       --subjects 01 02 \
       --glove-path /path/to/glove.6B.300d.txt \
       --target-rate 100 \
       --overwrite
     ```
   - Output: `derivatives/Models/glove/sub-XX/...` (100 Hz arrays and norms)

9. **C1 – Subject-level dRSA**
   - Direct: `python C1_dRSA_run.py sub-01 --analysis-name "$ANALYSIS_NAME"`
   - Output: `results/$ANALYSIS_NAME/single_subjects/*` (matrices, metadata, caches, plots)
   - SGE:  
     ```bash
     qsub -v ANALYSIS_NAME="$ANALYSIS_NAME" \
          -t 1-27 \
          s2_submit_C1_subject.sh \
          -- --analysis-name "$ANALYSIS_NAME" --lock-subsample-to-word-onset --allow-overlap
      
      qsub -v ANALYSIS_NAME=first_correlation_nolock_nooverlap \ # pass directly the analysis name
          -t 1 \
          s2_submit_C1_subject.sh
     ```

10. **C2 – Subject plots**
    - Direct: `python C2_plot_dRSA.py sub-01 --analysis-name "$ANALYSIS_NAME"`
    - Output: refreshed PNG plots in `results/$ANALYSIS_NAME/single_subjects/`
    - SGE: `qsub -v ANALYSIS_NAME="$ANALYSIS_NAME" -t 1-27 s2_submit_C2_plot.sh -- --analysis-name "$ANALYSIS_NAME"`

11. **D1 – Group cluster analysis**
    - Direct:  
      ```bash
      python D1_group_cluster_analysis.py \
        --analysis-name "$ANALYSIS_NAME" \
        --subjects $(seq -w 1 27) \
        --models "Envelope" "Phoneme Voicing" "Word Frequency" "GloVe" "GloVe Norm"
      ```
      ```bash
      e.g.:
      python D1_group_cluster_analysis.py --analysis-name "first_correlation_nolock_nooverlap" --subjects $(seq -w 1 27) --models "Envelope" "Phoneme Voicing" "Word Frequency" "GloVe" "GloVe Norm"
      ```
    - Output: `results/$ANALYSIS_NAME/group_level/*` (PNG, PDF, NPZ)
    - SGE: 
      - `qsub -v ANALYSIS_NAME="$ANALYSIS_NAME" s2_submit_D1_group.sh --subjects $(seq -w 1 27)`
      - e.g.: `qsub -v ANALYSIS_NAME=first_correlation_nolock_nooverlap s2_submit_D1_group.sh --subjects $(seq -w 1 27)`
      - Omit the `--` separator when calling this helper; it forwards arguments directly to the Python command.

12. **Wrapper alternatives (optional)**
    - Direct (full pipeline):  
      ```bash
      python pipeline_wrapper.py \
        --subjects 01 02 \
        --glove-path /path/to/glove.6B.300d.txt \
        --analysis-name "$ANALYSIS_NAME" \
        --overwrite
      ```
    - Direct (low storage):  
      ```bash
      python pipeline_wrapper_low_storage.py \
        --subjects 01 02 \
        --glove-path /path/to/glove.6B.300d.txt \
        --analysis-name "$ANALYSIS_NAME" \
        --continue-on-error
      ```
    - SGE:  
      - `qsub -v ANALYSIS_NAME="$ANALYSIS_NAME" s2_submit_python_wrapper.sh -- --subjects 01 02 --glove-path /path/to/glove.6B.300d.txt --analysis-name "$ANALYSIS_NAME" --overwrite`  
      - `qsub -v ANALYSIS_NAME="$ANALYSIS_NAME" s2_submit_python_wrapper_low_storage.sh -- --subjects 01-27 --glove-path /path/to/glove.6B.300d.txt --analysis-name "$ANALYSIS_NAME" --continue-on-error --keep-reports`

When launching any qsub job, always forward the analysis name with `-v ANALYSIS_NAME=…` so every node writes into the same `results/<analysis_name>/` tree.

### B6_gpt_next_prediction.py
Build GPT next-token prediction features aligned to the 100 Hz MEG timeline. For each token in the spoken stimulus, the model computes the distribution over the next token given left context, projects it to a compact feature space, and aligns features by evenly splitting each word’s duration across its tokens.

- Input: Preprocessed concatenation metadata and BIDS events (A1/A2 outputs). Optionally a local GPT2 checkpoint in `derivatives/Models/gpt2/` to avoid downloads.
- Output (per subject) under `derivatives/Models/gpt_next/<sub>/concatenated/`:
  - `sub-XX_concatenated_gpt_next_100Hz.npy` (features × timepoints)
  - `sub-XX_concatenated_gpt_predictability_100Hz.npy` (1 × timepoints)
  - `sub-XX_concatenated_gpt_surprisal_100Hz.npy` (1 × timepoints)
  - Metadata JSON and optional diagnostic plot
- Key options:
  - `--subjects sub-01 sub-02` – participants to process
  - `--hf-model PATH|NAME` – defaults to `derivatives/Models/gpt2` if present, else `gpt2`
  - `--context-tokens 512` – max left context tokens
  - `--projection pca-embedding|expected-embedding` – default now `pca-embedding`
  - `--components 64` – PCA components on expected embeddings (0 to disable)
  - `--load-projection / --save-projection` – reuse or persist a PCA basis to keep it fixed across subjects
  - `--positions-per-forward 256` – positions computed per forward pass (lower uses less memory)
  - `--target-rate 100.0` – output rate in Hz
  - `--device auto` – auto/cpu/cuda/mps
  - `--noise-fill` / `--no-noise-fill` and `--noise-scale` – control Gaussian gap filling and coverage mask output
  - `--plot` – save diagnostic plot (plus a context-usage histogram)
- Usage
  ```bash
  # Activate env
  source .venv/bin/activate

  # Use local GPT2 weights (recommended)
  python B6_gpt_next_prediction.py \
    --subjects sub-01 \
    --hf-model derivatives/Models/gpt2 \
    --context-tokens 512 \
    --components 64 \
    --plot --overwrite --log-level INFO \
    --save-projection derivatives/Models/gpt_next/pca_basis_ipca.pkl

  # Or fetch from HF Hub if needed
  python B6_gpt_next_prediction.py --subjects 01 --hf-model gpt2 --plot
  ```

Once generated, these models are automatically picked up by `C1_dRSA_run.py` if present. By default only "GPT Next-Token" (correlation RDM) and "GPT Surprisal" (euclidean) are registered; predictability is currently disabled.

### B6_gpt_next_logprob_svd.py (recommended)
Next-token model using streaming SVD directly on log-probability vectors with a single global projection basis pooled across all stories, plus story-level caching. This preserves distribution geometry and greatly reduces redundant compute across subjects.

- Global basis: `derivatives/Models/gpt_next/global_svd_basis.pkl` (TruncatedSVD, randomized).
- Story caches: `derivatives/Models/gpt_next/story_cache/<task>/` (reduced per-token features, surprisal, predictability, token map, hashes).
- Mass-based sparsification: keep smallest K s.t. cumulative probability ≥ `--topk-mass` (default 0.99), cap at `--topk` (default 4096).
- Scalars: computed from full logits (no truncation). Surprisal[0] = NaN by design.

- Usage
  ```bash
  source .venv/bin/activate

  # First subject: fit global basis, build caches, assemble
  python B6_gpt_next_logprob_svd.py \
    --subjects sub-01 \
    --hf-model derivatives/Models/gpt2 \
    --context-tokens 512 \
    --components 64 \
    --topk 4096 --topk-mass 0.99 \
    --svd-fit-sample 100000 \
    --plot --overwrite

  # Additional subjects: reuses global basis and story caches
  python B6_gpt_next_logprob_svd.py --subjects sub-02 sub-03 --hf-model derivatives/Models/gpt2 --components 64 --plot
  ```

### C1 dRSA Smoke Test with GPT models
Run a lightweight C1 analysis that only includes the GPT models and locks subsample windows to word onsets (centered by default). Results are written into a dedicated analysis folder.

- Local (single subject):
  ```bash
  source .venv/bin/activate
  DRSA_MODELS="GPT Next-Token,GPT Surprisal" \
  python C1_dRSA_run.py sub-01 \
    --analysis-name gpt_smoke \
    --lock-subsample-to-word-onset \
    --allow-overlap
  ```
  - Writes to `results/gpt_smoke/single_subjects/`.
  - Requires `derivatives/preprocessed/sub-01/concatenated/sub-01_concatenated_word_onsets_sec.npy`.
  - Optional: append `--word-onset-alignment start` to reproduce the legacy start-aligned windows.

- Cluster (single subject smoke test):
  ```bash
  qsub -v ANALYSIS_NAME=gpt_smoke,DRSA_MODELS="GPT Next-Token,GPT Surprisal" \
       -t 1 \
       s2_submit_C1_subject.sh \
       -- --lock-subsample-to-word-onset --allow-overlap
  ```
  - Adjust `-t` to a range (e.g., `1-27`) to scale up after the smoke test.
  - Add `--word-onset-alignment start` after the double dash to keep the legacy alignment.

  Alternative (robust env forwarding on SGE): export first, then use `-V` to forward the shell environment so commas in variables aren’t split by `-v`.
  ```bash
  export DRSA_MODELS="GPT Next-Token,GPT Surprisal"
  qsub -V -v ANALYSIS_NAME=gpt_smoke \
       -t 1 \
       s2_submit_C1_subject.sh \
       -- --lock-subsample-to-word-onset --allow-overlap
  ```
  - Use the same `--word-onset-alignment start` suffix here if you prefer start-aligned windows.

Happy analysing!
- **Border QC helper**: after a run completes, use `python check_regr_boarder.py <analysis_name>` to overlay custom thresholds (edited directly inside `check_regr_boarder.py`) on top of the cached autocorrelation curves saved in `single_subjects/cache/regression_borders/`. The script loads the `.npz` data exported alongside each PNG, recomputes the border for the scripted thresholds, and writes comparison plots to `inspect_borders_*` folders. Pass `--metadata path/to/_metadata.json` when an analysis contains multiple subject runs, and optionally override the default threshold via `--default-threshold`.
